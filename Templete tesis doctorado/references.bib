@article{hamilton,
    author={Hamilton, William L.},
    title={Graph Representation Learning},
    journal={Synthesis Lectures on Artificial Intelligence and Machine Learning},
    volume={14},
    number={3},
    pages={1-159},
    publisher={Morgan and Claypool}
}

@inbook{gatti,
    author = {Alice Gatti and Zhixiong Hu and Tess Smidt and Esmond G. Ng and Pieter Ghysels},
    title = {Deep Learning and Spectral Embedding for Graph Partitioning},
    booktitle = {Proceedings of the 2022 SIAM Conference on Parallel Processing for Scientific Computing (PP)},
    chapter = {},
    pages = {25-36},
    doi = {10.1137/1.9781611977141.3},
    URL = {https://epubs.siam.org/doi/abs/10.1137/1.9781611977141.3},
    eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611977141.3},
        abstract = { Abstract We present a graph bisection and partitioning algorithm based on graph neural networks. For each node in the graph, the network outputs probabilities for each of the partitions. The graph neural network consists of two modules: an embedding phase and a partitioning phase. The embedding phase is trained first by minimizing a loss function inspired by spectral graph theory. The partitioning module is trained through a loss function that corresponds to the expected value of the normalized cut. Both parts of the neural network rely on SAGE convolutional layers and graph coarsening using heavy edge matching. The multilevel structure of the neural network is inspired by the multigrid algorithm. Our approach generalizes very well to bigger graphs and has partition quality comparable to METIS, Scotch and spectral partitioning, with shorter runtime compared to METIS and spectral partitioning. }
}

@article{gap,
  title={GAP: Generalizable Approximate Graph Partitioning Framework},
  author={Azade Nazi and Will Hang and Anna Goldie and Sujith Ravi and Azalia Mirhoseini},
  journal={ArXiv},
  year={2019},
  volume={abs/1903.00614}
}