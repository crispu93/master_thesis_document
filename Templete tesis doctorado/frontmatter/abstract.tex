

\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}

%\begin{SingleSpace}
\initial{T}he design of algorithms that solve Combinatorial Optimization problems is a challenging task due to their intractable nature. One of the fundamental and most studied problem in the area is the Graph Partitioning problem. In recent years, several Deep Learning strategies have been developed to deal with this and other Combinatorial Optimization problems, which have successfully shown satisfactory results. One of the famous ones is the Generalizable Approximate Partitioning (GAP) framework. This work aims to present an extension of this framework that works for more general graphs and generalizes well to large ones.

One of the first observations made in this research is that the GAP framework uses an architecture based on Graph Convolutional Networks (GCN's) which tends to be slow for big graphs. Therefore, significant modifications were carried out to reduce the computation time without losing the power of the original framework and at the same time preserve the advantages that Graph Neural Networks have.

In addition, it was noted that GAP requires graphs with node features due to the model architecture chosen by its authors. That dependency was eliminated by using a random walk approach to generate node features. This was an important modification because the algorithm now relies purely on the graph's structure which is enough for the Graph Partitioning Problem.

The last part of this research shows how to use a negative sampling technique to accelerate and improve the process of finding balanced partitions without sacrificing the quality of said partitions. The proposed algorithm shows results comparable with widely used partitioning algorithms like METIS or SCOTCH.
%\end{SingleSpace}

\clearpage